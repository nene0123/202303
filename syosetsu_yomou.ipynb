{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests openpyxl bs4\n",
        "# 실행 전 필요라이브러리 설치"
      ],
      "metadata": {
        "id": "0E_mJtCaBJTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8427c73c-a0cd-4822-9fe4-22a9c31b22d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (3.0.10)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSoVVqTg_1E5"
      },
      "outputs": [],
      "source": [
        "import os, threading, json, re, time, datetime, pathlib\n",
        "from pprint import pprint\n",
        "\n",
        "import openpyxl, bs4, requests\n",
        "\n",
        "save_path = \"result\"  # 파일이 저장될 폴더의 이름을 지정할 수 있다.\n",
        "ses = requests.Session()\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "hdr = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
        "}\n",
        "\n",
        "\n",
        "def get_books(word, page, delay=0, order=\"new\", minlastup=None, maxlastup=None):\n",
        "    \"\"\"\n",
        "    검색함수 : 해당 키워드로 검색 했을 때 X번째 페이지의 데이터들을 수집한다.\n",
        "    :param word: 검색 키워드\n",
        "    :param page: 해당 페이지\n",
        "    :param delay: 함수 실행시 발생 하는 추가 딜레이\n",
        "    :param order: 검색 타입\n",
        "    :param minlastup: 검색 범위 시작 날짜\n",
        "    :param maxlastup: 검색 범위 마지막 날짜\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    url = \"https://yomou.syosetu.com/search.php\"\n",
        "    payload = {\n",
        "        'word': word,\n",
        "        'order_former': 'search',\n",
        "        'order': order,\n",
        "        'notnizi': '1',\n",
        "        'p': page,\n",
        "    }\n",
        "\n",
        "    if minlastup:\n",
        "        payload['minlastup'] = minlastup\n",
        "    if maxlastup:\n",
        "        payload['maxlastup'] = maxlastup\n",
        "\n",
        "    res = ses.get(url, params=payload, headers=hdr)\n",
        "    soup = bs4.BeautifulSoup(res.content, \"html.parser\")\n",
        "    books = soup.select(\"div.searchkekka_box\")\n",
        "\n",
        "    result = []\n",
        "    for book in books:\n",
        "        title_tag = book.select_one(\"div.novel_h > a.tl\")\n",
        "        title = title_tag.text.strip()\n",
        "        contents_url = title_tag['href']\n",
        "\n",
        "        state_tag = book.select_one(\"td.left\")\n",
        "        state = state_tag.text.strip()\n",
        "\n",
        "        genre = \"\"\n",
        "        keywords = []\n",
        "        tmp_tags = book.select(\"td:nth-of-type(2) > a\")\n",
        "        for tag in tmp_tags:\n",
        "            tag_href = tag['href']\n",
        "            if \"genre\" in tag_href:\n",
        "                genre = tag.text.strip()\n",
        "            elif \"word\" in tag_href:\n",
        "                keywords.append(tag.text.strip())\n",
        "\n",
        "        book_content = book.text.strip()\n",
        "        review_p = re.compile(\"レビュー数： (.*)件\")\n",
        "        s = review_p.search(book_content)\n",
        "        review = 0\n",
        "        if s:\n",
        "            review_text = s.groups()[0]\n",
        "            review_text = review_text.replace(\" \", \"\").replace(\",\", \"\")\n",
        "            review = int(review_text)\n",
        "\n",
        "        recent_p = re.compile(\"最終更新日：(\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2})\")\n",
        "        s = recent_p.search(book_content)\n",
        "        recent = None\n",
        "        if s:\n",
        "            recent_text = s.groups()[0]\n",
        "            recent = datetime.datetime.strptime(recent_text, \"%Y/%m/%d %H:%M\")\n",
        "\n",
        "        item = {\n",
        "            'title': title,\n",
        "            'state': state,\n",
        "            'genre': genre,\n",
        "            'keywords': keywords,\n",
        "            'review': review,\n",
        "            'recent': recent,\n",
        "            'url': contents_url,\n",
        "        }\n",
        "\n",
        "        result.append(item)\n",
        "\n",
        "    time.sleep(delay)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_contents(url, delay=0):\n",
        "    \"\"\"\n",
        "    선택된 소설의 세부 에피소드들의 정보를 수집한다.\n",
        "    :param url: 선택된 소설의 url\n",
        "    :param delay: 추가 딜레이\n",
        "    :return: \n",
        "    \"\"\"\n",
        "    res = ses.get(url, headers=hdr)\n",
        "    soup = bs4.BeautifulSoup(res.content, \"html.parser\")\n",
        "    contents_list = soup.select(\"dl.novel_sublist2\")\n",
        "    contents = []\n",
        "    for cont in contents_list:\n",
        "        title_tag = cont.select_one(\"dd > a\")\n",
        "        title = title_tag.text.strip()\n",
        "        cont_url = title_tag['href']\n",
        "\n",
        "        update_tag = cont.select_one(\"dt\")\n",
        "        modify_tag = update_tag.select_one(\"span\")\n",
        "        if modify_tag:\n",
        "            modify_tag.decompose()\n",
        "        update_text = update_tag.text.strip()\n",
        "        update = datetime.datetime.strptime(update_text, \"%Y/%m/%d %H:%M\")\n",
        "\n",
        "        item = {\n",
        "            'title': title,\n",
        "            'update': update,\n",
        "            'url': f\"https://ncode.syosetu.com{cont_url}\",\n",
        "        }\n",
        "        contents.append(item)\n",
        "\n",
        "    time.sleep(delay)\n",
        "\n",
        "    return contents\n",
        "\n",
        "\n",
        "def make_excel(genres, keywords, months, subtitle=None):\n",
        "    \"\"\"\n",
        "    검색된 데이터들을 바탕으로 엑셀파일을 생성한다.\n",
        "    :param genres:\n",
        "    :param keywords:\n",
        "    :param months:\n",
        "    :param subtitle: 엑셀파일 결과물의 이름에 반영할 부제목\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    wb = openpyxl.Workbook()\n",
        "    genre_sht = wb.create_sheet('장르', 0)\n",
        "    keyword_sht = wb.create_sheet('키워드', 1)\n",
        "    month_sht = wb.create_sheet('연도별 월별 작품수', 2)\n",
        "\n",
        "    genre_sht.append([\"장르\", \"소설 수\"])\n",
        "    keyword_sht.append([\"키워드\", \"소설 수\"])\n",
        "    month_sht.append([\"날짜\", \"소설 수\"])\n",
        "\n",
        "    for (g, count) in sorted(list(genres.items()), key=lambda x: x[1], reverse=True):\n",
        "        genre_sht.append([g, count])\n",
        "\n",
        "    for (k, count) in sorted(list(keywords.items()), key=lambda x: x[1], reverse=True):\n",
        "        keyword_sht.append([k, count])\n",
        "\n",
        "    for (m, count) in sorted(list(months.items()), key=lambda x: x[0]):\n",
        "        month_sht.append([m, count])\n",
        "\n",
        "    dstring = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    filepath = f\"{save_path}/결과_{dstring}.xlsx\"\n",
        "    if subtitle:\n",
        "        filepath = f\"result/결과_{subtitle}_{dstring}.xlsx\"\n",
        "    wb.save(filepath)\n",
        "\n",
        "    print(f\"엑셀 파일 생성 완료 : {filepath}\")\n",
        "\n",
        "\n",
        "def process(word, number_of_pages, delay, order=\"new\", subtitle=None, minlastup=None, maxlastup=None):\n",
        "    \"\"\"\n",
        "    전체적인 프로세스를 진행한다.\n",
        "    1. 검색 키워드로 소설 리스트 수집\n",
        "    2. 리스트에서 나온 소설 url을 이용하여 소설 에피소드들의 데이터를 수집\n",
        "    3. 1번과 2번 과전 반복\n",
        "    4. 엑셀파일 생성\n",
        "    \"\"\"\n",
        "    \n",
        "    genres = dict()\n",
        "    months = dict()\n",
        "    keywords = dict()\n",
        "\n",
        "    for page in range(1, number_of_pages + 1):\n",
        "        books = get_books(word, page, order=order, minlastup=minlastup, maxlastup=maxlastup)\n",
        "        for n, book in enumerate(books[:]):\n",
        "            contents_url = book['url']\n",
        "            contents = get_contents(contents_url, delay=delay)\n",
        "            print(f\"[ {(page - 1) * 20 + n + 1:3} ][ contents : {len(contents):3} ] : {book}\")\n",
        "            bkeywords = book['keywords']\n",
        "            bgenre = book['genre']\n",
        "\n",
        "            for bk in bkeywords:\n",
        "                if not bk in keywords:\n",
        "                    keywords[bk] = 1\n",
        "                else:\n",
        "                    keywords[bk] += 1\n",
        "\n",
        "            if not bgenre in genres:\n",
        "                genres[bgenre] = 1\n",
        "            else:\n",
        "                genres[bgenre] += 1\n",
        "\n",
        "            for content in contents[:1]:\n",
        "                date = content['update'].strftime(\"%Y-%m\")\n",
        "                if not date in months:\n",
        "                    months[date] = 1\n",
        "                else:\n",
        "                    months[date] += 1\n",
        "\n",
        "    make_excel(genres, keywords, months, subtitle=subtitle)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "pages 와 delay를 조절하여 테스트 진행\n",
        "pages는 해당 키워드로 검색하여 찾는 페이지의 수를 지정\n",
        "하나의 페이지에 20개의 소설이 검색되니 2000개의 소설에 대해서 검색을 진행하려면 100페이지로 설정\n",
        "딜레이는 기본적으로 1을 주고 진행\n",
        "\"\"\"\n",
        "pages = 1\n",
        "delay = 1\n",
        "process(\"悪役令嬢\", pages, delay)"
      ],
      "metadata": {
        "id": "qDl8qRrZTsmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \"\"\"\n",
        "    종합포인트순으로 나열\n",
        "    \"\"\"\n",
        "pages = 1\n",
        "delay = 1\n",
        "process(\"悪役令嬢\", pages, delay, order=\"hyoka\", subtitle=\"종합포인트\")"
      ],
      "metadata": {
        "id": "_9B6NAtsF0gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \"\"\"\n",
        "    투고날짜 순으로 나열\n",
        "    \"\"\"\n",
        "pages = 1\n",
        "delay = 1\n",
        "process(\"悪役令嬢\", pages, delay, subtitle=\"초창기\", minlastup=\"2013/03/01\", maxlastup=\"2017/01/01\")"
      ],
      "metadata": {
        "id": "Od3V2T9qF0pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}